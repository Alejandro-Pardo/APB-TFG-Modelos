{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'T2/train/2019/data'\n",
    "# Recorrer todos los archivos en el directorio\n",
    "for path in os.listdir(directory):\n",
    "    filename = os.path.join(directory, path)\n",
    "    try:\n",
    "        tree = ET.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        user = root.find('ID').text\n",
    "        writings = root.findall('WRITING')\n",
    "        text = ' '.join((writing.find('TEXT').text).strip() for writing in writings)\n",
    "        new_data= [user, text]\n",
    "        data_list.append(new_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.DataFrame(data_list, columns=['user', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['text'] = train1['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('T2/train/2019/T1_erisk_golden_truth.txt', 'r')\n",
    "for line in file:\n",
    "    usuario = line.split()[0]\n",
    "    clasificacion = int(line.split(' ')[1])\n",
    "    train1.loc[train1['user'] == usuario, 'label'] = int(clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.to_csv('train1_TFG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "processed_users =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'T2/train/2018/test'\n",
    "# Recorrer todos los archivos en el directorio\n",
    "for path in os.listdir(directory):\n",
    "    filename = os.path.join(directory, path)\n",
    "    try:\n",
    "        tree = ET.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        user = root.find('ID').text\n",
    "        writings = root.findall('WRITING')\n",
    "        text = ' '.join((writing.find('TEXT').text).strip() for writing in writings)\n",
    "        if user in processed_users:\n",
    "            index = processed_users.index(user)\n",
    "            data_list[index][1] += text\n",
    "        else:\n",
    "            new_data= [user, text]\n",
    "            data_list.append(new_data)\n",
    "            processed_users.append(user)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.DataFrame(data_list, columns=['user', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['text'] = train2['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('T2/train/2018/test/risk-golden-truth-test.txt', 'r')\n",
    "for line in file:\n",
    "    usuario = line.split()[0]\n",
    "    clasificacion = int(line.split(' ')[1])\n",
    "    train2.loc[train2['user'] == usuario, 'label'] = int(clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.to_csv('train2_TFG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenar 2018 y 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('train1_TFG.csv')\n",
    "train2 = pd.read_csv('train2_TFG.csv')\n",
    "#concatenar los dos dataframes\n",
    "train = pd.concat([train1, train2])\n",
    "train.to_csv('train_TFG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar los datos de entrenamiento de 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "processed_users =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory1 = 'T2/train/2018/train/negative_examples'\n",
    "directory2 = 'T2/train/2018/train/positive_examples'\n",
    "# Recorrer todos los archivos en el directorio\n",
    "for directory in [directory1, directory2]:\n",
    "    for path in os.listdir(directory):\n",
    "        filename = os.path.join(directory, path)\n",
    "        try:\n",
    "            tree = ET.parse(filename)\n",
    "            root = tree.getroot()\n",
    "            user = root.find('ID').text\n",
    "            writings = root.findall('WRITING')\n",
    "            text = ' '.join((writing.find('TEXT').text).strip() for writing in writings)\n",
    "            if user in processed_users:\n",
    "                index = processed_users.index(user)\n",
    "                data_list[index][1].join(text)\n",
    "            else:\n",
    "                new_data= [user, text]\n",
    "                data_list.append(new_data)\n",
    "                processed_users.append(user)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(data_list, columns=['user', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('T2/train/2018/train/risk_golden_truth.txt', 'r')\n",
    "for line in file:\n",
    "    usuario = line.split()[0]\n",
    "    clasificacion = int(line.split(' ')[1])\n",
    "    test.loc[test['user'] == usuario, 'label'] = int(clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_TFG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_TFG.csv')\n",
    "test = pd.read_csv('test_TFG.csv')\n",
    "final = pd.concat([train, test])\n",
    "final.to_csv('data_TFG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATS TFG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carga los datos\n",
    "data = pd.read_csv('data_TFG.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade la columna de longitud\n",
    "data['length_text'] = data['text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el tamaño del gráfico\n",
    "fig_size = (20, 10)\n",
    "plt.figure(figsize=fig_size)\n",
    "\n",
    "#eleminar filas cuya lenght sea 0\n",
    "data = data[data['length_text'] != 0]\n",
    "# Define las etiquetas personalizadas\n",
    "etiquetas_personalizadas = {0: 'No anorexia', 1: 'Anorexia'}\n",
    "\n",
    "# Obtiene las etiquetas únicas\n",
    "labels = sorted(data[\"label\"].unique())\n",
    "\n",
    "# Crea un gráfico para cada etiqueta\n",
    "for name in labels:\n",
    "    # Selecciona los datos para esta etiqueta\n",
    "    subset = data[data['label'] == name]\n",
    "    # Dibuja el gráfico de densidad de Kernel\n",
    "    sns.kdeplot(subset['length_text'], label=etiquetas_personalizadas[name], legend=True)\n",
    "\n",
    "# Configura los ejes y la leyenda\n",
    "plt.xlabel('Número de tokens del texto original', fontsize=14 )\n",
    "plt.ylabel('Densidad', fontsize=14)\n",
    "plt.legend(prop={'size': 15}, title='Etiquetas', loc=\"upper right\")\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene un resumen estadístico de la columna 'length_text'\n",
    "resumen = data['length_text'].describe(percentiles=[0, 0.25, 0.50, 0.75, 0.95])\n",
    "\n",
    "print(resumen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carga los datos\n",
    "data = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length_text'] = data['text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el tamaño del gráfico\n",
    "fig_size = (20, 10)\n",
    "plt.figure(figsize=fig_size)\n",
    "\n",
    "# Define las etiquetas personalizadas\n",
    "etiquetas_personalizadas = {0: 'No anorexia', 1: 'Anorexia'}\n",
    "\n",
    "# Obtiene las etiquetas únicas\n",
    "labels = sorted(data[\"label\"].unique())\n",
    "\n",
    "# Crea un gráfico para cada etiqueta\n",
    "for name in labels:\n",
    "    # Selecciona los datos para esta etiqueta\n",
    "    subset = data[data['label'] == name]\n",
    "    # Dibuja el gráfico de densidad de Kernel\n",
    "    sns.kdeplot(subset['length_text'], label=etiquetas_personalizadas[name], legend=True)\n",
    "\n",
    "# Configura los ejes y la leyenda\n",
    "plt.xlabel('Número de tokens del texto original', fontsize=14 )\n",
    "plt.ylabel('Densidad', fontsize=14)\n",
    "plt.legend(prop={'size': 15}, title='Etiquetas', loc=\"upper right\")\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene un resumen estadístico de la columna 'length_text'\n",
    "resumen = data['length_text'].describe(percentiles=[0, 0.25, 0.50, 0.75, 0.95])\n",
    "\n",
    "print(resumen)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
